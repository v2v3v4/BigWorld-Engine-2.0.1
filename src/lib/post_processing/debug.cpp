/******************************************************************************
BigWorld Technology 
Copyright BigWorld Pty, Ltd.
All Rights Reserved. Commercial in confidence.

WARNING: This computer program is protected by copyright law and international
treaties. Unauthorized use, reproduction or distribution of this program, or
any portion of this program, may result in the imposition of civil and
criminal penalties as provided by law.
******************************************************************************/

#include "pch.hpp"
#include "debug.hpp"
#include "moo/render_context.hpp"
#include "romp/geometrics.hpp"
#include "romp/py_render_target.hpp"

#ifndef CODE_INLINE
#include "debug.ipp"
#endif

DECLARE_DEBUG_COMPONENT2( "PostProcessing", 0 )

BW_INIT_SINGLETON_STORAGE( PostProcessing::Debug )

namespace PostProcessing
{
// Python statics
PY_TYPEOBJECT( Debug )

PY_BEGIN_METHODS( Debug )
	/*~ function Debug.phaseUV
	 *	@components{ client, tools }
	 *
	 *	This method returns the texture coordinates for the given effect/phase
	 *	pair, packed into a Vector4 as ( bl.x, bl.y, tr.x, tr.y ), or
	 *	 l, b, r, t )
	 *
	 *	@param	effect	index of the effect within the PostProcessing chain
	 *	@param	phase	index of the phase within the effect
	 *	@param	nEffects number of effects
	 *	@param	nPhases	number of phases within the desired effect
	 *
	 *	@return	Vector4	packed uv coordinates of the phase
	 */
	PY_METHOD( phaseUV )
PY_END_METHODS()

PY_BEGIN_ATTRIBUTES( Debug )
	/*~ attribute Debug.renderTarget
	 *	@components{ client, tools }
	 *	
	 *	The Debug object requires a render target to do its work.  With this
	 *	attribute you can provide the Debug object with a render target of
	 *	whatever size and format you like.
	 *
	 *	@type PyRenderTarget.
	 */
	PY_ATTRIBUTE( renderTarget )
PY_END_ATTRIBUTES()


/*~ class PostProcessing.Debug
 *	@components{ client, tools }
 *	This class records each step of the entire PostProcessing chain into
 *	a render target, allowing you to see every single step.
 *
 *	This kind of debugging is required as the individual phases in the
 *	PostProcessing chain may (and should) be re-using render targets.
 */
/*~ function PostProcessing.Debug
 *	@components{ client, tools }
 *	Factory function to create and return a PostProcessing Debug object.
 *
 *	@return A new PostProcessing Debug object.
 */
PY_FACTORY_NAMED( Debug, "Debug", _PostProcessing )

Debug::Debug( PyTypePlus *pType ):
		PyObjectPlus( pType ),
		enabled_(true),
		nEffects_(0),
		nPhases_(0),
		effect_(0),
		phase_(0)
{
};


/**
 *	This method should be called to let the debug object know an entire
 *	chain is about to be drawn.  It resets some internal variables.
 *	@param	nEffects	number of effects in the chain.
 */
void Debug::beginChain( uint32 nEffects )
{
	nEffects_ = (int32)nEffects;
	effect_ = -1;
}


/**
 *	This method should be called to let the debug object know an effect
 *	is about to draw.  It resets some internal variables.
 *	@param	nPhases	number of phases in the effect.
 */
void Debug::beginEffect( uint32 nPhases )
{
	nPhases_ = (int32)nPhases;
	phase_ = 0;
	effect_++;
}


/**
 *	This method draws a grey box where a phase would be recorded.  It indicates
 *	the phase has been temporarily disabled. 
 */
void Debug::drawDisabledPhase()
{
	if ( pRT_.hasObject() && pRT_->pRenderTarget().hasObject() )
	{
		RECT r = this->nextPhase();

		if (pRT_->pRenderTarget()->push())
		{
			Geometrics::drawRect( Vector2((float)r.left, (float)r.top), Vector2((float)r.right, (float)r.bottom), 0x80808080 );
			pRT_->pRenderTarget()->pop();
		}		
	}
}


/**
 *	This method advances to the next phase in the output chain.
 *
 *	It returns the viewport rectangle that a phase containing
 *	its own method for previewing should draw into.
 *
 *	Internally it increments the phase index, meaning for a phase you
 *	should call nextPhase once and once onlye.
 */
RECT Debug::nextPhase()
{
	float rtWidth = (float)pRT_->pRenderTarget()->width();
	float rtHeight = (float)pRT_->pRenderTarget()->height();
	Vector4 uvs = this->phaseUV( effect_, phase_, nEffects_, nPhases_ );
	RECT r;
	r.left = (uint32)(uvs[0] * rtWidth);
	r.top = (uint32)(rtHeight - uvs[3] * rtHeight);
	r.right = (uint32)(uvs[2] * rtWidth);
	r.bottom = (uint32)(rtHeight - uvs[1] * rtHeight);
	phase_++;
	return r;
}


/**
 *	This method takes a snapshot of the supplied render target and copies
 *	it in our internally held render target, in some spot calculated by
 *	the effect/phase id we are currently in.
 *
 *	@param	pRT		Render target containing the results of the latest phase.
 */
void Debug::copyPhaseOutput( Moo::RenderTargetPtr pRT )
{
	if ( !pRT_ )
	{
		return;
	}

	if (effect_ == 0 && phase_ == 0 && pRT_->pRenderTarget()->push())
	{
		Moo::rc().device()->Clear( 0, NULL, D3DCLEAR_TARGET, 0x00000000, 1, 0 );
		pRT_->pRenderTarget()->pop();
	}

	RECT r = this->nextPhase();

	if (r.right-r.left <= 0 || r.bottom-r.top <= 0)
	{
		return;
	}

	ComObjectWrap<DX::Surface> src;
	ComObjectWrap<DX::Surface> dst;
	pRT_->pRenderTarget()->pSurface(dst);
	if (pRT.hasObject())
	{
		pRT->pSurface(src);
	}
	else
	{
		src = Moo::rc().getRenderTarget(0);
	}

	Moo::rc().device()->StretchRect( src.pComObject(), NULL, dst.pComObject(), &r, D3DTEXF_LINEAR );
}


/**
 *	This method returns the texture coordinates for the given effect/phase
 *	pair, packed into a Vector4 as ( bl.x, bl.y, tr.x, tr.y ), or
 *	( l, b, r, t )
 *
 *	@param	effect	index of the effect within the PostProcessing chain
 *	@param	phase	index of the phase within the effect
 *	@param	nEffects number of effects
 *	@param	nPhases	number of phases within the desired effect
 *
 *	@return	Vector4	packed uv coordinates of the phase
 */
Vector4 Debug::phaseUV( uint32 effect, uint32 phase, uint32 nEffects, uint32 nPhases )
{
	//u,v how many effects to draw in the x,y directions
	float effectU = ceilf(sqrtf((float)nEffects));
	float effectV = ceilf((float)nEffects/effectU);
	//effect grid size
	float effectW = 1.f / effectU;
	float effectH = 1.f / effectV;
	//effect location
	float effectX = fmodf((float)effect,effectU) * effectW;
	float effectY = floorf(effect/effectU) * effectH;

	//u,v how many phases to draw in the x,y directions within
	//our effect region
	float phaseU = ceilf(sqrtf((float)nPhases));
	float phaseV = ceilf((float)nPhases/phaseU);
	//phase grid size
	float phaseW = effectW / phaseU;
	float phaseH = effectH / phaseV;
	//effect location
	float phaseX = fmodf((float)phase, phaseU) * phaseW + effectX;
	float phaseY = floorf(phase/phaseU) * phaseH + effectY;

	return Vector4(phaseX, phaseY, phaseX + phaseW, phaseY + phaseH);
}


PyRenderTargetPtr Debug::pRT() const
{
	return pRT_;
}


PyObject * Debug::pyGetAttribute( const char *attr )
{
	PY_GETATTR_STD();
	return PyObjectPlus::pyGetAttribute(attr);
}


int Debug::pySetAttribute( const char *attr, PyObject *value )
{
	PY_SETATTR_STD();
	return PyObjectPlus::pySetAttribute(attr,value);
}


PyObject* Debug::pyNew(PyObject* args)
{
	return new Debug;
}
}	//namespace PostProcessing
